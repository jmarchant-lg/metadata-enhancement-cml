{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wikipedia\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import re\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'continue' not properly in loop (<ipython-input-2-c6688f4e9639>, line 281)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-c6688f4e9639>\"\u001b[1;36m, line \u001b[1;32m281\u001b[0m\n\u001b[1;33m    continue\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'continue' not properly in loop\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "############ CAST LIST ###############\n",
    "######################################\n",
    "\n",
    "def get_cast_list(page,debug=False):\n",
    "    cast_text = page.section(\"Cast\")\n",
    "    if cast_text is not None:\n",
    "        initial_cast_list = []\n",
    "        bullet_points = cast_text.split(\"\\n\")\n",
    "        if debug:\n",
    "            print(\"Cast text not empty. Found {} paragraphs\".format(len(bullet_points)))\n",
    "        if len(bullet_points) == 1:\n",
    "            bullet_points_new = bullet_points[0].split(\":\")\n",
    "            if debug:\n",
    "                print(\"Split by :, found {} sections\".format(len(bullet_points_new)))\n",
    "                print(\"First section: {}\".format(bullet_points_new[0]))\n",
    "            for i in range(0,len(bullet_points_new)):\n",
    "                part = bullet_points_new[i]\n",
    "                if \" as \" in part:\n",
    "                    initial_cast_list.append(part.split(\" as \")[-1])\n",
    "        else:\n",
    "            if bullet_points[0].split(\":\")[-1] == \"\":\n",
    "                s = 1\n",
    "            else:\n",
    "                s = 0\n",
    "            for i in range(s,len(bullet_points)):\n",
    "                parts = bullet_points[i].split(\":\")\n",
    "                if len(parts) == 1:\n",
    "                    parts = bullet_points[i].split(\",\")\n",
    "                name = parts[0]\n",
    "                if debug:\n",
    "                    print(\"Name isolated: within '{}'\".format(name))\n",
    "                if \" as \" in name:\n",
    "                    initial_cast_list.append(name.split(\" as \")[1])\n",
    "                else:\n",
    "                    if name == \"\":\n",
    "                        continue\n",
    "                    else:\n",
    "                        initial_cast_list.append(name)\n",
    "        cast_list = cast_list_all_combinations(initial_cast_list)\n",
    "        final_cast_list = clean_up_cast_list(cast_list)\n",
    "        return final_cast_list\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def cast_list_all_combinations(cast_list):\n",
    "    all_combos = []\n",
    "    for name in cast_list:\n",
    "        names = name.split(\" \")\n",
    "        if len(names) == 2:\n",
    "            all_combos.append(names[0])\n",
    "            all_combos.append(names[1])\n",
    "        elif len(names) >= 3:\n",
    "            if '\"' in name:\n",
    "                quote_name = name.split('\"')[1] # takes name inside quotation marks\n",
    "                all_combos.append(quote_name)\n",
    "            all_combos.append(names[0])\n",
    "            all_combos.append(names[-1])\n",
    "            all_combos.append(names[0] + \" \" + names[-1])\n",
    "        all_combos.append(name)\n",
    "    return all_combos\n",
    "\n",
    "def clean_up_cast_list(cast_list):\n",
    "    final_cast_list = []\n",
    "    for cast in cast_list:\n",
    "        if len(cast) > 1:\n",
    "            if cast[0].isupper() and len(cast) < 50:\n",
    "                if cast != \"The\" and \"also\" not in cast:\n",
    "                    if \"/\" not in cast and \"(\" not in cast and \")\" not in cast:\n",
    "                        final_cast_list.append(cast)\n",
    "    reduced_cast_list = set(final_cast_list)\n",
    "    return reduced_cast_list\n",
    "\n",
    "######################################\n",
    "############## TAGGING ###############\n",
    "######################################\n",
    "\n",
    "def tag_all_sentences(sentences,cast_list,debug=False):\n",
    "    tagged_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tag_list = tag_cast_in_sentence(sentence,cast_list,debug)\n",
    "        sentence = sentence.replace(\"\\'s\",\"'s\")\n",
    "        if len(tag_list) != 0:\n",
    "            tagged_sentences.append( (sentence,tag_list) )\n",
    "    return tagged_sentences\n",
    "\n",
    "def tag_cast_in_sentence(sentence,cast_list,debug=False):\n",
    "    tag_list = []\n",
    "    sentence = sentence + \" \"\n",
    "    for name in cast_list:\n",
    "        name_alternatives = [name + \" \", name + \"'\", name + \".\", name + \",\"]\n",
    "        for name in name_alternatives:\n",
    "            locations = [m.start() for m in re.finditer(name,sentence)]\n",
    "            for location in locations:\n",
    "                tag_list.append((location,location+len(name)-1,\"PERSON\"))\n",
    "        \n",
    "    final_tag_list = clean_up_tag_list(tag_list,debug)\n",
    "    final_tag_list = combine_connected_tags(final_tag_list,debug)\n",
    "    return final_tag_list\n",
    "\n",
    "######################################\n",
    "######### CLEAN TAG LIST #############\n",
    "######################################\n",
    "\n",
    "def clean_up_tag_list(tag_list,debug=False):\n",
    "    if debug:\n",
    "        print(\"Input: {}\".format(tag_list))\n",
    "    tag_list = list(set(tag_list))\n",
    "    tag_to_remove = find_tag_to_remove(tag_list,debug)\n",
    "    while tag_to_remove != \"\":\n",
    "        if debug:\n",
    "            print(\"Removing {}\".format(tag_to_remove))\n",
    "        tag_list.remove(tag_to_remove)\n",
    "        tag_to_remove = find_tag_to_remove(tag_list,debug)\n",
    "    new_tag_list = combine_connected_tags(tag_list,debug)\n",
    "    final_tag_list = remove_overlapping_tags(new_tag_list,debug)\n",
    "    return final_tag_list\n",
    "        \n",
    "def find_tag_to_remove(tag_list,debug=False):\n",
    "    for tag in tag_list:\n",
    "        start = tag[0]\n",
    "        end = tag[1]\n",
    "        length = end-start\n",
    "        for tag2 in [x for x in tag_list if x is not tag]:\n",
    "            start2 = tag2[0]\n",
    "            end2 = tag2[1]\n",
    "            length2 = end2-start2\n",
    "            if start == start2 or end == end2:\n",
    "                if debug:\n",
    "                    print(\"A: {} - {}, B: {} - {}\".format(start,end,start2,end2))\n",
    "                if length >= length2:\n",
    "                    return tag2\n",
    "                elif length2 > length:\n",
    "                    return tag\n",
    "    return \"\"\n",
    "\n",
    "def combine_connected_tags(tag_list,debug=False):\n",
    "    for tag in tag_list:\n",
    "        start = tag[0]\n",
    "        end = tag[1]\n",
    "        for tag2 in [x for x in tag_list if x is not tag]:\n",
    "            start2 = tag2[0]\n",
    "            end2 = tag2[1]\n",
    "            if end+1 == start2:\n",
    "                tag_list.remove(tag2)\n",
    "                tag_list.remove(tag)\n",
    "                new_tag = (start,end2,\"PERSON\")\n",
    "                tag_list.append(new_tag)\n",
    "                if debug:\n",
    "                    print(\"Combined {} and {} into {}\".format(tag,tag2,new_tag))\n",
    "                tag_list = combine_connected_tags(tag_list,debug)\n",
    "            elif end2+1 == start:\n",
    "                tag_list.remove(tag2)\n",
    "                tag_list.remove(tag)\n",
    "                new_tag = (start2,end,\"PERSON\")\n",
    "                tag_list.append(new_tag)\n",
    "                if debug:\n",
    "                    print(\"Combined {} and {} into {}\".format(tag2,tag,new_tag))\n",
    "                tag_list = combine_connected_tags(tag_list,debug)\n",
    "    # Only get here if no connected tags\n",
    "    return tag_list\n",
    "\n",
    "def find_overlapping_tag(tag_list,debug=False):\n",
    "    for tag in tag_list:\n",
    "        start = tag[0]\n",
    "        end = tag[1]\n",
    "        length = end-start\n",
    "        for tag2 in [x for x in tag_list if x is not tag]:\n",
    "            start2 = tag2[0]\n",
    "            end2 = tag2[1]\n",
    "            length2 = end2-start2\n",
    "            if (end2 >= start and end2 <= end) or (end >= start2 and end <= end2):\n",
    "                if length >= length2:\n",
    "                    return tag2\n",
    "                else:\n",
    "                    return tag\n",
    "    return \"\"\n",
    "\n",
    "def remove_overlapping_tags(tag_list,debug=False):\n",
    "    tag_list = list(set(tag_list))\n",
    "    overlapping_tag = find_overlapping_tag(tag_list,debug)\n",
    "    while overlapping_tag != \"\":\n",
    "        if debug:\n",
    "            print(\"Removing {}\".format(overlapping_tag))\n",
    "        tag_list.remove(overlapping_tag)\n",
    "        overlapping_tag = find_overlapping_tag(tag_list,debug)\n",
    "    return tag_list  \n",
    "\n",
    "######################################\n",
    "############### PLOT #################\n",
    "######################################\n",
    "\n",
    "def get_plot_sentences(page,debug=False):\n",
    "    # TODO: Add catch for \"NoneType has no attribute replace\" error when plot/ plot sentence is empty\n",
    "    plot_text = page.section(\"Plot\")\n",
    "    plot_text_split = plot_text.replace(\"\\n\",\" \")\n",
    "    plot_text_final = plot_text_split.replace(\"\\'s\",\"'s\")\n",
    "    plot_sentences = plot_text_final.split(\". \")\n",
    "    return plot_sentences\n",
    "\n",
    "######################################\n",
    "######## GET TRAINING DATA ###########\n",
    "######################################\n",
    "\n",
    "def get_training_data_from_all_pages(list_of_titles,debug=False):\n",
    "    training_data = []\n",
    "    for title in list_of_titles:\n",
    "        try:\n",
    "            page = wikipedia.WikipediaPage(title=title)\n",
    "        except wikipedia.exceptions.DisambiguationError:\n",
    "            print(\"Disambiguous Title Name, Skipping {}\".format(title))\n",
    "            continue\n",
    "        except wikipedia.exceptions.PageError:\n",
    "            print(\"No page found with title {}\".format(title))\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            current_data = get_training_data_from_page(page,debug)\n",
    "        except Exception as e:\n",
    "            print(\"Error for Title: {}: {}\".format(title,e))\n",
    "            current_data = []\n",
    "            continue\n",
    "        \n",
    "        if current_data != []:\n",
    "            training_data += current_data\n",
    "            print(\"Added {} new training examples successfully from {}\".format(len(current_data),title))\n",
    "        else:\n",
    "            print(\"No cast found from {}\".format(title))\n",
    "    return training_data\n",
    "\n",
    "def get_training_data_from_page(page,debug=False):\n",
    "    cast_list = get_cast_list(page,debug)\n",
    "    if cast_list != []:\n",
    "        if debug:\n",
    "            print(\"Cast List:{}\".format(sorted(cast_list)))\n",
    "        plot_sentences = get_plot_sentences(page,debug)\n",
    "        tagged_sentences = tag_all_sentences(plot_sentences,cast_list,debug)\n",
    "        return tagged_sentences\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "######################################\n",
    "######## GET TRAINING DATA ###########\n",
    "######################################\n",
    "\n",
    "def create_training_test_sets(csv_file,number_of_titles,training_file,test_file,debug=False):\n",
    "    # Uses a 80:20 train:test split\n",
    "    t1 = time.time()\n",
    "    titles_df = pd.read_csv(csv_file)\n",
    "    \n",
    "    train_limit = int(number_of_titles*0.8)\n",
    "    list_of_titles_train = titles_df[\"primaryTitle\"].tolist()[:train_limit]\n",
    "    training_data = get_training_data_from_all_pages(list_of_titles_train,debug)\n",
    "    print(\"Training Data Collected\")\n",
    "    pickle.dump(training_data, open(training_file, 'wb'))\n",
    "    print(\"Training Data Stored\")\n",
    "    \n",
    "    list_of_titles_test = titles_df[\"primaryTitle\"].tolist()[train_limit:number_of_titles]\n",
    "    test_data = get_training_data_from_all_pages(list_of_titles_test,debug)\n",
    "    print(\"Test Data Collected\")\n",
    "    pickle.dump(test_data, open(test_file, 'wb'))\n",
    "    print(\"Test Data Stored\")\n",
    "    t2 = time.time()\n",
    "    print(\"Took {} seconds = {} seconds per page\".format(round(t2-t1,2),round((t2-t1)/number_of_titles,2)))\n",
    "    \n",
    "######################################\n",
    "######### TESTER FUNCTIONS ###########\n",
    "######################################\n",
    "\n",
    "def test_one_title(title):\n",
    "    print(\"Working on {}\".format(title))\n",
    "    try:\n",
    "        page = wikipedia.WikipediaPage(title=title)\n",
    "        print(\"Page Found\")\n",
    "        tagged_sentences = get_training_data_from_page(page,debug=True)\n",
    "    except wikipedia.exceptions.DisambiguationError:\n",
    "        print(\"Disambiguous Title Name, Skipping {}\".format(title))\n",
    "        continue\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        print(\"No page found with title {}\".format(title))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
